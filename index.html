<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 24px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px;
      font-weight: 700
    }
    
    venue {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-style: italic
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 40px;
    }

    email {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px;
    }
    
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    span.highlight {
      background-color: #ffffd0;
    }
    .avatar{
        margin-top: 50px; 
        width:200px; 
        height:200px; 
        border-radius:200px; 
    }

    .vaniila_image{
        width:200px; 
        height:200px;
    }

  </style>
  <!-- <link rel="icon" type="image/png" href="images/seal_icon.png"> -->
  <title>Bo Chen</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="70%" valign="middle">
              <p align="center">
                <name>Bo Chen (ÈôàÊ≥¢)</name>
                <br>
                <email>allanchen224 [at] gmail [dot] com</email>
                <p align=center>
                  <a href="mailto:allanchen224@gmail.com">Email</a> &nbsp/&nbsp
                  <a href="https://github.com/allanchen95">Github</a> &nbsp/&nbsp
                  <a href="https://scholar.google.com/citations?user=ZHtOJowAAAAJ&hl=en&authuser=2">Google Scholar</a>
                </p>
              </p>
              <p>I am now a first year PhD student at Knowledge Engineering Group(KEG), Department of Computer Science and 
                Technology of Tsinghua Universiy, under the surpervision of <a href="http://keg.cs.tsinghua.edu.cn/jietang">Prof. Jie Tang</a>. My research interests include data integration, name disambiguation and reasoning on KG.</p>
              </p>
            </td>
            <td width="30%">
              <img src="images/github_photo.png" class="avatar">
            </td>
          </tr>
        </table>
        <!--
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Research</heading>
              <p>
                I'm interested in Natural Language Processing, Deep Learning and Computational Linguistics. Much of my research is about Natural Language Generation (mostly) and Natural Language Understanding (as a tool for better generation).
              </p>
              <p>
                You can find some details in <a href="https://medium.com/@spsayakpaul/an-interview-with-thomas-wolf-chief-science-officer-at-hugging-face-ee585f782997">this interview I gave to PyImageSearch</a> or <a href="https://lionbridge.ai/articles/how-to-build-a-social-ai-an-interview-with-nlp-researcher-thomas-wolf/">this earlier interview I gave to LionBridge.AI</a> where I discuss the work we do at Huggingface, current trends in AI/NLP and my unusual background.
              </p>
            </td>
          </tr>
        </table>
        -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>News</heading>
            </td>
          </tr>
        </table>
        
        <ul>
            <li>on <strong>May, 2021</strong>, 
              We will hold the name disambiguation competition at IJCAI'21 Competition Track based on the newly-released version(na-v3) of 
              <a href="https://www.aminer.cn/whoiswho">WhoIsWho</a> dataset. We honestly invite all the researchers of interest to attend our competition!       
        </ul>
       
        <!--
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Blog</heading>
              <p>
                I like to explain clearly what I have learned and this has lead to a few blog posts that were quite interesting to other as well I guess (they totalise over a quarter million views at the end of 2018). I will try to continue writing things like that when I find the time. I used to be a teacher during my PhD and I do miss teaching. Blogging is my substitute.
              </p>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
            <td width="25%"><img src="images/training.jpeg" alt="Training Neural Nets on Larger Batches" width="160"></td>
            <td width="75%" valign="center">
              <p>
                <a href="https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255">
                  <papertitle>üí• Training Neural Nets on Larger Batches: Practical Tips for 1-GPU, Multi-GPU & Distributed setups</papertitle>
                </a>
                <p>I've spent most of 2018 training models that could barely fit 1-4 samples/GPU.
                  But SGD usually needs more than few samples/batch for decent results.
                  I wrote a post gathering practical tips I use, from simple tricks to multi-GPU code & distributed setups</p>
              </p>
            </td>
          </tr>
        </table>
        
        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

          <tr >
            <td width="25%">
              <div class="one">
                <img src='images/meaning.jpeg'>
              </div>
            </td>
            <td valign="top" width="75%">
              <a href="https://medium.com/huggingface/learning-meaning-in-natural-language-processing-the-semantics-mega-thread-9c0332dfe28e">
                <papertitle>‚õµ Learning Meaning in Natural Language Processing‚Ää‚Äî‚ÄäThe Semantics Mega-Thread</papertitle>
              </a>
              <p>A summary, overview and map of a huge discussion on learning meaning in NLP that happened on Twitter in August 2018 with more than a 100 comments and great inputs from Matt Gardner, Yoav Goldberg, Sam Bowman, Emily M. Bender, Graham Neubig, Jeremy Howard, Tal Linzen, Jacob Andreas, Ryan D. Cotterell ...</p>
            </p>
        </td>
          </tr>

          <tr >
            <td width="25%">
              <div class="one">
                <img src='images/100_times.jpeg'>
              </div>
            </td>
            <td valign="top" width="75%">
              <a href="https://medium.com/huggingface/100-times-faster-natural-language-processing-in-python-ee32033bdced">
                <papertitle>üöÄ 100 Times Faster Natural Language Processing in Python</papertitle>
              </a>
              <p>How you can make your Python NLP module 50-100 times faster by use spaCy's internals and a bit of Cython magic! Womes with a Jupyter notebook with examples processing over 80 millions words per sec.
                </p>
            </p>
        </td>
          </tr>

          <tr >
            <td width="25%">
              <div class="one">
                <img src='images/words.png'>
              </div>
            </td>
            <td valign="top" width="75%">
              <a href="https://medium.com/huggingface/universal-word-sentence-embeddings-ce48ddc8fc3a">
                <papertitle>üìöThe Current Best of Universal Word Embeddings and Sentence Embeddings</papertitle>
              </a>
              <p>A post summarizing recent developments in Universal Word/Sentence Embeddings that happend over 2017/early-2018 and future trends. With ELMo, InferSent, Google's Universal Sentence embeddings, learning by multi-tasking... Written with <a href="https://twitter.com/SanhEstPasMoi">Victor Sanh</a>.
                </p>
            </p>
        </td>
          </tr>

          <tr >
            <td width="25%">
              <div class="one">
                <img src='images/meta_learning.jpeg'>
              </div>
            </td>
            <td valign="top" width="75%">
              <a href="https://medium.com/huggingface/from-zero-to-research-an-introduction-to-meta-learning-8e16e677f78a">
                <papertitle>üê£ From zero to research‚Ää‚Äî‚ÄäAn introduction to Meta-learning</papertitle>
              </a>
              <p>To introduce <a href="https://arxiv.org/abs/1803.10631">the work we presented at ICLR 2018</a>, I drafted a visual & intuitive introduction to Meta-Learning. In this post, I start by explaining what‚Äôs meta-learning in a very visual and intuitive way. Then, we code a meta-learning model in PyTorch and I share some of the lessons learned on this project.
                </p>
            </p>
        </td>
          </tr>


          <tr >
            <td width="25%">
              <div class="one">
                <img src='images/train_coref.jpeg'>
              </div>
            </td>
            <td valign="top" width="75%">
              <a href="https://medium.com/huggingface/how-to-train-a-neural-coreference-model-neuralcoref-2-7bb30c1abdfe">
                <papertitle>‚ú®How to train a neural coreference model‚Äî Neuralcoref 2</papertitle>
              </a>
              <p>A post describing the internals of <a href="https://github.com/huggingface/neuralcoref">NeuralCoref</a>. Neuralcoref is designed to strike a good balance between accuracy and speed/simplicity, using a rule-based mention detection module, a constrained number of features and a simple feed-forward neural network. This post describes how the coreference resolution system works and how to train it.
            </p>
        </td>
          </tr>

          <tr >
            <td width="25%">
              <div class="one">
                <img src='images/emotions.jpeg'>
              </div>
            </td>
            <td valign="top" width="75%">
              <a href="https://medium.com/huggingface/how-to-train-a-neural-coreference-model-neuralcoref-2-7bb30c1abdfe">
                <papertitle>Understanding emotions‚Ää‚Äî‚Ääfrom Keras to pyTorch
                </papertitle>
              </a>
              <p>A post accompanying our open-sourcing of <a href="https://github.com/huggingface/torchMoji">torchMoji</a>, a PyTorch adaptation of MIT's DeepMoji model. In this post, I detail several points that arose during the reimplementation of a Keras model in PyTorch: how to make a custom pyTorch LSTM with custom activation functions,
                how the PackedSequence object works and is built,
                how to convert an attention layer from Keras to pyTorch,
                how to load your data in pyTorch: DataSets and smart Batching,
                how to reproduce Keras weights initialization in pyTorch.
                </p>
            </p>
        </td>
          </tr>

          <tr >
            <td width="25%">
              <div class="one">
                <img src='images/sota_coref.jpeg'>
              </div>
            </td>
            <td valign="top" width="75%">
              <a href="https://medium.com/huggingface/state-of-the-art-neural-coreference-resolution-for-chatbots-3302365dcf30">
                <papertitle>State-of-the-art neural coreference resolution for chatbots
                </papertitle>
              </a>
              <p>A post accompanying our open-sourcing of <a href="https://github.com/huggingface/neuralcoref">NeuralCoref</a>. It comprise an introduction to the field of co-reference resolution and describes how a coreference resolution system works in practice.
                </p>
            </p>
        </td>
          </tr>
        </table>


        -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Preprints</heading>
            </td>
          </tr>
        </table>
        
        <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
              <td width="25%"><img width="100%" src="images/coad.png"></td>
              <td width="75%" valign="top">
                <p>
                  <a href="data/coad.pdf">
                    <papertitle>COAD: Contrastive Pre-training with Adversarial Fine-tuning for Zero-shot Expert Linking</papertitle>
                  </a>
                  <br>
                  <strong>Bo Chen</strong>, Jing Zhang, Xiaokang Zhang, Xiaobin Tang, Lingfan Cai, Hong Chen, Cuiping Li, Peng Zhang, Jie Tang
                  <br>
                  <venue> <a herf = "https://arxiv.org/abs/2012.11336">Arxiv</a></venue>, 2021
                </p>
              </td>
            </tr>
        </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td>
            <heading>Publications</heading>
          </td>
        </tr>
      </table>
      
      <table width="100%" align="center" border="0" cellpadding="20">
        <tr>
          <td width="25%"><img width="100%" src="images/Neuro_symblic_reasoning.png"></td>
          <td width="75%" valign="top">
            <p>
              <a href="data/Neuro_symblic_reasoning_Ai_open'21.pdf">
                <papertitle>Neural, Symbolic and Neural-Symbolic Reasoning on Knowledge Graphs</papertitle>
              </a>
              <br>
              Jing Zhang, <strong>Bo Chen</strong>, Lingxi Zhang, Xirui Ke, Haipeng Ding
              <br>
              <venue> <a herf = "http://www.keaipublishing.com/en/journals/ai-open/">AI Open Journal</a>, 2021</venue>
            </p>
          </td>
        </tr>
        <tr>
            <td width="25%"><img width="100%" src="images/conna.png"></td>
            <td width="75%" valign="top">
              <p>
                <a href="data/CONNA_TKDE'20.pdf">
                  <papertitle>CONNA: Addressing Name Disambiguation on The Fly</papertitle>
                </a>
                <br>
                <strong>Bo Chen</strong>, Jing Zhang, Jie Tang, Lingfan Cai, Zhaoyu Wang, Shu Zhao, Hong Chen and Cuiping Li.
                <br>
                <venue> <a herf = "https://www.computer.org/csdl/journal/tk">IEEE Transaction on Knowledge and Data Engineering (TKDE)</a>, 2020</venue>, [<a href="https://github.com/allanchen95/TKDE-2019-CONNA">Github</a>]
              </p>
            </td>
          </tr>
          <tr>
            <td width="25%"><img width="100%" src="images/Bert_int.png"></td>
            <td width="75%" valign="top">
              <p>
                <a href="data/Bert_int_ijcai'20.pdf">
                  <papertitle>BERT-INT:A BERT-based Interaction Model For Knowledge Graph Alignment</papertitle>
                </a>
                <br>
                Xiaobin Tang, Jing Zhang, <strong>Bo Chen</strong>, Yang Yang, Hong Chen, Cuiping Li
                <br>
                <venue> <a herf = "https://ijcai20.org/">International Joint Conference on Artificial Intelligence (IJCAI)</a>, 2020</venue>, [<a href="https://github.com/kosugi11037/bert-int">Github</a>]
                <br>
                (Full Paper, acceptance rate: 12.6%)
              </p>
            </td>
          </tr>
          <tr>
            <td width="25%"><img width="100%" src="images/jarka.png"></td>
            <td width="75%" valign="top">
              <p>
                <a href="data/jarka_PAKDD'20.pdf">
                  <papertitle>JarKA: Modeling Attribute Interactions for Cross-lingual Knowledge Alignment</papertitle>
                </a>
                <br>
                <strong>Bo Chen</strong>, Jing Zhang, Xiaobin Tang, Hong Chen, and Cuiping Li
                <br>
                <venue> <a herf = "http://www.pakdd2020.org/"> Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD)</a>, 2020</venue>, [<a href="https://github.com/allanchen95/PAKDD-20-JarKA">Github</a>]
                <br>
                (Full Paper, acceptance rate: 21%)
              </p>
            </td>
          </tr>
          <tr>
            <td width="25%"><img width="100%" src="images/hrl.png"></td>
            <td width="75%" valign="top">
              <p>
                <a href="data/HRL_AAAI'19.pdf">
                  <papertitle>Hierarchical Reinforcement Learning for Course Recommendation in MOOCs</papertitle>
                </a>
                <br>
                Jing Zhang, Bowen Hao, <strong>Bo Chen</strong>, Cuiping Li, Hong Chen and Jimeng Sun
                <br>
                <venue> <a herf = "https://aaai.org/Conferences/AAAI-19/"> AAAI Conference on Artificial Intelligence (AAAI)</a>, 2019</venue>, [<a href="https://github.com/jerryhao66/HRL">Github</a>]
                <br>
                (Full Paper, acceptance rate: 16.2%)
              </p>
            </td>
          </tr>
          <tr>
            <td width="25%"><img width="100%" src="images/mego2vec.png"></td>
            <td width="75%" valign="top">
              <p>
                <a href="data/mego2vec_cikm'18.pdf">
                  <papertitle>MEgo2Vec: Embedding Matched Ego Networks for User Alignment Across Social Networks</papertitle>
                </a>
                <br>
                Jing Zhang, <strong>Bo Chen</strong>, Xianming Wang, Hong Chen, Cuiping Li, Fengmei Jin, Guojie Sone, Yutao Zhang
                <br>
                <venue> <a herf = "https://www.cikm2018.units.it/"> International Conference on Information and Knowledge Management (CIKM)</a>, 2018</venue>, [<a href="https://github.com/allanchen95/MEgo2Vec-Embedding-Matched-Ego-Networks-for-User-Alignment-Across-Social-Networks">Github</a>]
                <br>
                (Full Paper, acceptance rate: 17%)
              </p>
            </td>
          </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td>
            <heading>Projects</heading>
            <p>
              These are some open-sourced projects.
            </p>
            </td>
        </tr>
      </table>
      
      <table width="100%" align="center" border="0" cellpadding="20">
        <tr>
          <!-- <td width="25%"><img src="images/sandbox.jpg" alt="sandbox"></td> -->
          <td width="75%" valign="top">
            <p>
              <a href="https://www.aminer.cn/whoiswho">
                <papertitle>WhoIsWho</papertitle>
              </a>
              <p>
                WhoIsWho is the world‚Äôs largest manually-labeled paper name disambiguation(NA) benchmark up to now, which consists about 
                <b>900,000+</b> papers belonging to <b>70,000+</b> authors, <b>1,000+</b> names, and we also comprehensively define 
                two basic tasks, Continuous Name Disambiguation and Name disambiguation from Scatch in NA domain with corresponding SOTA baselines.
                (see deatils <a href="https://www.aminer.cn/whoiswho">WhoIsWho</a>).
              </p>
            </p>
          </td>
        </tr>
    </table>
   


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td>
            <heading>Education</heading>
          </td>
        </tr>
      </table>
      
      <ul>
          <li><strong>September, 2013 - June, 2017</strong>, Bachelor, Department of Computer Science and Technology, 
            Information School, Renmin University of China.
          <li><strong>September, 2017 - June, 2020</strong>, Master, Department of Computer Science and Technology, 
            Information School, Renmin University of China, under the surpervision of <a href="https://xiaojingzi.github.io/">Associate Prof. Jing Zhang</a> and <a href = "http://info.ruc.edu.cn/academic_professor.php?teacher_id=56">Prof. Hong Chen</a>.
          <li><strong>September, 2021 - </strong>, PhD, Department of Computer Science and Technology, Tsinghua University, 
            under the surpervision of <a href="http://keg.cs.tsinghua.edu.cn/jietang">Prof. Jie Tang</a>.                 
      </ul>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
        <tr>
          <td>
            <br>
            <p align="center">
              <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=220&t=tt&d=y3Ykzbs7sa5vLKnTtzveQ8rCDJgYDkXVPtudeDSubN0&co=2d78ad&cmo=3acc3a&cmn=ff5353&ct=ffffff'></script>
            </p>
          </td>
        </tr>
      </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="2">
                  <a href="https://github.com/jonbarron/jonbarron_website"><strong>Created from Jonathan T. Barron's template</strong></a>
                  </font>
              </p>
            </td>
          </tr>
        </table>
        <script type="text/javascript">
          var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
        </script>
        <script type="text/javascript">
          try {
            var pageTracker = _gat._getTracker("UA-7580334-1");
            pageTracker._trackPageview();
          } catch (err) {}
        </script>
        </td>
    </tr>
  </table>
</body>

</html>
